import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import pandas as pd
from tqdm import tqdm

class WhiskeyScraper:
    def __init__(self, url, output_csv_name):
        self.url = url
        self.output_csv_name = output_csv_name
        self.driver = None
        self.data = []

    def setup_driver(self):
        options = Options()
        options.add_argument('--headless')
        self.driver = webdriver.Chrome("/usr/lib/chromium-browser/chromedriver", options=options)

    def login(self, username, password):
        self.driver.get(self.url)
        self.driver.find_element(By.XPATH, "/html/body/div[1]/div[1]/div/div[3]/form/div[1]/div/input").send_keys(username)
        self.driver.find_element(By.XPATH,"/html/body/div[1]/div[1]/div/div[3]/form/div[2]/div/input").send_keys(password)
        self.driver.find_element(By.XPATH,"/html/body/div[1]/div[1]/div/div[3]/form/div[3]/div/button").click()
        
    def get_page_links(self):
        page = requests.get(self.url)
        soup = BeautifulSoup(page.text, "html.parser")
        atags = soup.find_all('a', {'class' : 'clickable'})
        links = [atag['href'] for atag in atags]
        return links

    def extract_whiskey_data(self, links):
        for link in tqdm(links, desc="Scraping Progress"):
            self.driver.get(link)
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')

            try:
                price = soup.find('div', class_="block-price").find_all('p')[-1].get_text()
            except:
                price = 'N/A'
                
            community_blocks = soup.find_all('div', class_="wb--community-block")
            
            if len(community_blocks) > 1 and price != 'N/A':
                users = community_blocks[1].find_all('th', scope='row')
                ratings = community_blocks[1].find_all('div', class_="wb--rating")
                
                for user, rating in zip(users, ratings):
                    self.data.append({
                        'whiskey': link.split('/')[-1],
                        'user': user.get_text().strip('\n'),
                        'rating': rating.get_text().strip('\n').split('\n')[0],
                        'price': price,
                        'url': link
                    })
    
    def save_to_csv(self):
        df = pd.DataFrame(self.data)
        df.to_csv(self.output_csv_name)
        

if __name__ == "__main__":
    USERNAME = "whiskie_coder"
    PASSWORD = "whiskie_coder"

    new_releases_scraper = WhiskeyScraper("https://www.whiskybase.com/whiskies/new-releases?bottle_date_year=2022&bottler_id=&brand_id=&vintage_year=&type_id=&itemsforsale=&votes=",
                                          'Whiskey_Released_in_2022_Data.csv')
    new_releases_scraper.setup_driver()
    new_releases_scraper.login(USERNAME, PASSWORD)
    links = new_releases_scraper.get_page_links()
    new_releases_scraper.extract_whiskey_data(links)
    new_releases_scraper.save_to_csv()

    # Repeat the same process for top 1000 whiskies
